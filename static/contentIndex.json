{"2022/are-we-writing-good-tests":{"title":"Are we writing good tests?","links":[],"tags":["tests","tdd","acceptance-tests","rant"],"content":"\nIn the past few years I became more and more addicted by tests. In the first stage of this disease I remember try to test every single happy and unhappy path of a flow, reach 100% code coverage, running tests against real databases and so on. For sure, it is not ideal and I totally understand the reason today.\nAlthough I was very excited with writing tests and see all the ‚Äúpasses‚Äù in the CI, I have not stopped to search for more resources and examples, and one day I came across an article about TDD. I don‚Äôt recall the exact article and it was not the first time I heard about the topic but that time I was bite.\n\nI finally landed at a company with everything in place: large code base extensively tested, unit, e2e, integration tests and all sort of those running in the CI for every PR, a dream for my old myself\n\nAt that point I was not ready to put TDD in practice, or at least I thought I wasn‚Äôt, so my journey increasing test coverage and writing as much tests I can to cover edge cases have continued, specially in two occasions where I was leading teams and pushed so hard in that direction. The time goes on and I finally landed at a company with everything in place: large code base extensively tested, unit, e2e, integration tests and all sort of those running in the CI for every PR, a dream for my old myself.\nIt‚Äôs not hard to foresee how a large code base, with hundred of developers individually testing each component becomes hard to maintain. Every single change requires fixes in many tests and this started to bother me. Specially in cases where you are working in a new feature, it‚Äôs supposed you don‚Äôt need to fix old tests since you are not breaking existing behavior, but this is not what happens in fact.\nI came across TDD again, quickly I noticed that we were writing bad tests, tests too tightly coupled to the implementation instead to the behavior. It was not uncommon to have 3 or 4 layers of mocks when writing tests, and now I know that this is result of a bad design, a design without tests in mind, which results in bad components very tangled, in fact it is not a problem with tests but with bad production code.\n\nwe were writing bad tests, tests too tightly coupled to the implementation instead to the behavior [‚Ä¶] in fact it is not a problem with tests but with bad production code\n\nDoes TDD lead to good design? Yes, it does. It certainly does because it‚Äôs impossible to write tangled code, coupled components when you start with tests, and it is due to a simple premisse, we do not write production code hard to test when starting from tests.\nIt‚Äôs just a rant for sure, but I feel like my journey through the Acceptance Tests and TDD is just starting, and to be honest I‚Äôm very excited with all of this üòÖ\nReferences:\n\n\nContinuous Delivery ‚Äî Awesome channel by Dave Farley;\n\n\nDoes TDD really lead to good design;\n\n\nToo many others to mention, hopefully I can come back here to do it in follow up rants.\n\n"},"2023/append-only-tables":{"title":"Append-Only Tables: Simplifying Database Persistence in Domain-Driven Design","links":[],"tags":["ddd","event-sourcing"],"content":"\nIn the software development world, Domain-Driven Design (DDD) and Event Sourcing have become rather popular because they provide effective frameworks for creating scalable and maintainable systems. Using append-only files in databases is an interesting way to simplify the persistence layer in this situation. Developers can avoid the complications involved with conventional Object-Relational Mapping (ORM) solutions by persisting events in a single table and depending on them to reconstruct the application state. We will examine the potential of this method and talk about how it simplifies DDD‚Äôs persistence layer in this article.\n\nDevelopers can replay the events sequentially to reconstruct the application state [‚Ä¶] allows developers to extend their domain models without having to deal with the headaches of database schema migrations, and it also makes debugging and auditing easier.\n\nThe Append-Only Advantage\nTo maintain data consistency, the conventional relational database model frequently calls for elaborate update procedures and sophisticated schema designs. The append-only method, however, provides a more straightforward option. In this case, new records are appended to an existing table with each modification of the state, reflecting events that signify changes in the state.\nEvent Sourcing in Action\nA key idea in DDD is event sourcing, which is the process of constructing an application‚Äôs whole state from a series of events. This translates into recording each state transition as an immutable event in the context of database persistence. These events provide a thorough audit trail for the history of the application by capturing the purpose and context of modifications.\nDevelopers can replay the events sequentially to reconstruct the application state at any given time by saving the events in an append-only table. This allows developers to extend their domain models without having to deal with the headaches of database schema migrations, and it also makes debugging and auditing easier.\nSimplifying the Persistence Layer\nThe persistence layer is made simpler by the append-only file strategy, which does away with the need for intricate update procedures. There is no need to edit records that already exist because every state change is represented as an event and appended to the table. This removes common problems with updating records, like managing indexes, performing cascading updates, and guaranteeing data consistency.\nAdditionally, this method adheres to the immutability rules, which facilitates reasoning about the behavior of the system and lowers the possibility of adding subtle errors. Additionally, it offers a distinct division of responsibilities since the aggregate root handles event processing and state maintenance on its own, minimizing the need for outside components to maintain data consistency.\nScalability and Performance\nThe efficiency and scalability of a system can be greatly enhanced by the append-only model. Write operations become extremely efficient and contention issues associated to updating existing records are reduced because events are continuously appended to the table. Because of this, the method works especially well for systems that need strong audit capabilities or have a large write throughput.\nIn conclusion, leveraging append-only files in the context of DDD and Event Sourcing offers a compelling alternative to traditional ORM-based persistence layers. By embracing the simplicity of storing events in a single table, developers can streamline the management of application state, simplify debugging and auditing, and enhance system scalability. This approach aligns seamlessly with the principles of immutability and event-driven architectures, empowering developers to build more resilient and maintainable systems."},"2023/ddd-cqrs":{"title":"Don‚Äôt Jump the Gun: Understanding DDD Before Applying CQRS","links":[],"tags":["ddd","cqrs"],"content":"Modern software development frequently uses the architectural design pattern known as Command Query Responsibility Segregation (CQRS), which divides a system‚Äôs commands (write actions) and queries (read operations).\nSoftware development using the DDD methodology places a strong emphasis on the value of modeling the business domain within the system.\n\nDevelopers run the danger of building an unnecessarily complex system that is hard to comprehend and manage when they attempt to deploy CQRS from scratch without understanding DDD. CQRS is not a panacea, and it shouldn‚Äôt be used without taking into account the particular needs of the business domain.\nOne of the key advantages of CQRS is that it enables programmers to separately optimize a system‚Äôs read and write pathways. This enables read-heavy systems to scale separately from write-heavy systems, enhancing efficiency and cutting costs. Yet in order to achieve this separation, a well-designed domain layer is necessary, which can be extremely difficult without a firm grasp of DDD.\n\nit needs to have closed boundaries which aims to hide objects from the surface ‚Äî so how to list entities that are not even exposed by their aggregate root?\n\nA well-designed domain layer is usually a bad readable model, though. It‚Äôs inherently to the way we plan it: it needs to have closed boundaries which aims to hide objects from the surface ‚Äî so how to list entities that are not even exposed by their aggregate root?\nAlthough the domain layer‚Äôs goal is to provide a clear separation of concerns and a representation of the business domain, this does not always convert into a user-friendly interface or a model that non-technical stakeholders can easily grasp.\nThis issue is resolved by CQRS, which separates read and write processes so that programmers can separately optimize each. This means that although the write model can be tuned for speed and consistency, the read model can be created expressly for simple consumption by users or other systems.\nAs a result, even while CQRS is a powerful design that can considerably help software systems, it shouldn‚Äôt be implemented randomly without a solid understanding of DDD."},"2023/optimizing-your-software-testing-efforts-what-not-to-test":{"title":"Optimizing Your Software Testing Efforts - what not to test?","links":[],"tags":["tdd"],"content":"\nTesting is an essential part of software development, and it is crucial to ensure that the code being developed is functional and reliable. While testing is important, it is equally important to focus on what to test and what not to test. Testing every single component of a software system can be time-consuming, expensive, and unnecessary. In this article, we will discuss why it is not necessary to test 3rd party libraries, implementation details, and system calls.\nThird-Party Libraries\nThird-party libraries are often used in software development to save time and effort. These libraries are developed by other developers and are designed to perform specific functions. For example, a web developer may use a third-party library for managing forms, or a mobile app developer may use a third-party library for displaying ads. These libraries are usually well-tested and have been used by many other developers before.\nWhen it comes to testing, it is not necessary to test third-party libraries. These libraries are already tested by the developers who created them, and they are also used by many other developers in their projects. It is unlikely that there are any significant bugs or issues with these libraries. However, it is important to ensure that the library is compatible with the software system being developed. This can be done by testing the integration of the library with the system.\nImplementation Details\nImplementation details are the internal workings of the software system. These details include things like the data structures used, the algorithms used, and the code optimization techniques used. These details are not visible to the end-users of the software, and they do not affect the functionality of the software system.\nIt is not necessary to test implementation details because they do not affect the functionality of the software system. However, it is important to ensure that the implementation details are correct and efficient. This can be done through code reviews and other techniques.\nSystem Calls\nSystem calls are the interface between the software system and the operating system. System calls are used to perform operations such as file I/O, process management, and memory allocation. System calls are essential for the functioning of the software system, but they are not part of the software system itself.\nIt is not necessary to test system calls because they are part of the operating system and are already tested by the developers of the operating system. However, it is important to ensure that the software system is using the system calls correctly and efficiently. This can be done through code reviews and other techniques.\nIn conclusion, testing is an essential part of software development, but it is important to focus on what to test and what not to test. Third-party libraries, implementation details, and system calls do not need to be tested extensively, as they are already well-tested and do not affect the functionality of the software system. Instead, it is important to focus on testing the integration of these components with the software system and ensuring that they are being used correctly and efficiently."},"2023/sut":{"title":"SUT","links":[],"tags":["tdd","legacy-code","code-coverage"],"content":"In a previous article I mentioned how SUT class helped us to rebuild the application and business‚Ä¶\nThis is not a easy work at all, and many other practices like Feature Flags could be mentioned here as very important in the process but I‚Äôd like to dig a bit in this specific topic and focus this article in the SUT class.\nTo address this challenge, one effective approach is to use a System Under Test (SUT) class to abstract the implementation details and build more resilient tests that will still pass when implementation changes. In this article, we will discuss what an SUT class is, why it is useful, and how to use it to build more resilient tests.\n\nWhat is an SUT Class?\nAn SUT class, or System Under Test class, is a class that represents the system being tested. It provides an interface through which the test code can interact with the system being tested, without having to know the details of the implementation.\nIn other words, an SUT class is a way to abstract the implementation details of the system being tested and provide a clear and simple interface for testing.\nWhy is an SUT Class Useful?\nThere are several reasons why an SUT class is useful for testing:\n1. It abstracts the implementation details.\nAn SUT class abstracts the implementation details of the system being tested. This means that the test code does not need to know how the system works internally, which makes it easier to write and maintain tests.\n2. It provides a clear and simple interface for testing.\nAn SUT class provides a clear and simple interface for testing. This means that the test code can focus on testing the behavior of the system, rather than worrying about the implementation details.\n3. It makes tests more resilient to changes in implementation.\nAn SUT class makes tests more resilient to changes in implementation. Because the test code interacts with the system through the SUT class, changes to the implementation of the system are less likely to break the tests.\nHow to Use an SUT Class to Build Resilient Tests\nTo use an SUT class to build more resilient tests, follow these steps:\n1. Define the SUT class.\nDefine the SUT class to represent the system being tested. The SUT class should provide an interface for the test code to interact with the system, without exposing the implementation details.\n2. Write tests using the SUT class.\nWrite the tests using the SUT class. The test code should interact with the system through the SUT class, using the interface provided by the class.\n3. Test the behavior of the system, not the implementation.\nTest the behavior of the system, not the implementation. This means that the test code should focus on what the system does, rather than how it does it.\n4. Keep the SUT class up-to-date with changes in implementation.\nKeep the SUT class up-to-date with changes in implementation. If the implementation of the system changes, update the SUT class to reflect the changes. This will ensure that the tests continue to pass, even when the implementation changes.\n5. Refactor the SUT class if necessary.\nRefactor the SUT class if necessary. If the SUT class becomes too complex or difficult to maintain, consider refactoring it to simplify the interface or break it down into smaller, more manageable classes.\nConclusion\nUsing an SUT class to abstract the implementation details of a system can help build more resilient tests that are less likely to break when the implementation changes. By providing a clear and simple interface for testing, an SUT class allows the test code to focus on testing the behavior of the system, rather than worrying about how it works internally.\nTo use an SUT class effectively, define the class to represent the system being tested, write tests using the class, focus on testing the behavior"},"2023/thematic-sprints":{"title":"Thematic Sprints","links":[],"tags":["agile","sprints","sprint-planning"],"content":"Agile methodology is a well-liked strategy of developing software that places an emphasis on teamwork, adaptability, and constant improvement. The division of work into smaller, more manageable units, known as sprints, is one of the fundamental tenets of agile. A team works on a prioritized collection of items from a product backlog during sprints, which are time-boxed intervals that typically span two to four weeks. A version of this strategy is the use of ‚Äúthematic sprints,‚Äù where each sprint focuses on a different theme or objective. In this post, we‚Äôll examine the advantages of thematic sprints in agile software development.\n\nPrioritized and Concentrated Work\nTeams can concentrate on specific objectives during thematic sprints, which can aid in prioritizing work and removing distractions. The team can identify and prioritize the most important product backlog items that support a given theme by concentrating on that theme. By doing this, you can make sure that the work you‚Äôre doing is in line with the project‚Äôs general objectives and the demands of its users.\nEnhanced Cooperation\nSprints with a particular theme may promote teamwork. Team members can work more closely together and share information and expertise by concentrating on a particular theme. This may result in enhanced problem-solving, improved communication, and a greater sense of teamwork. Team members might come to a shared understanding of the project‚Äôs priorities and goals as they cooperate to accomplish a common aim.\nBetter Comments\nSprints with a specific theme may also result in improved stakeholder feedback. Teams can interact more closely with stakeholders who are invested in a given aspect of the project by concentrating on a particular subject. The team may be able to detect and address problems more rapidly as a result of receiving more regular and targeted feedback. Teams can change and improve more quickly if they receive input on certain features or functionality.\nShortened time to market\nSprints with a specific theme might hasten time-to-market as well. Teams can work more productively and efficiently by concentrating on particular themes, resulting in the delivery of features and functionality that are in line with user needs and project objectives. This can shorten the process duration and expense while also raising the final product‚Äôs quality.\nIncreased adaptability\nThematic sprints can also offer more versatility and flexibility. Teams can more easily change their goals and priorities as the project develops by splitting work into smaller, more manageable parts. Teams can also adjust more rapidly as user demands or project objectives change by concentrating on particular topics.\nThematic sprints can provide a variety of advantages when using agile approach to develop software, to sum up. Thematic sprints can assist teams in working more effectively and efficiently, producing better products that satisfy the demands of customers and stakeholders. They do this by offering focus, fostering cooperation, increasing feedback, accelerating time-to-market, and expanding flexibility. Using thematic sprints to keep your team on track and help it accomplish its objectives can help you enhance your agile development process."},"2023/turning-legacy-into-well-tested-code":{"title":"How we turned old legacy code into shiny well tested code.","links":[],"tags":["tdd","legacy-code","turbo"],"content":"Modernizing an old legacy system can be a daunting task for any software development team. One of the biggest challenges is to make changes without disrupting the existing system, which is often complex and difficult to understand. In this article, we will explain how we turned an old 10-year legacy system into a shiny new code by keeping all the data structure intact and writing executable specifications.\n\nThe legacy system we were tasked to modernize was a C# application with zero test coverage. The first step we took was to copy the entities‚Äô definition, following the exact same data structure defined in the original system. These classes were placed in the ‚Äúcore‚Äù or ‚Äúbusiness‚Äù layer, without any logic initially.\nNext, we created an application layer and wrote the first specification. We created a simple class called SUT (System Under Test) that mocked the repo interfaces. At this point, the repos were nothing other than simply interfaces defined in the business layer. We wrote the first use case, which was a simple operation depending on three other entities in the system. We created the entities without any constructor or validation, so mocking them and adding to a simple Collection based repo mock was very easy.\n\nThis approach allowed us to quickly iterate and improve the system while ensuring that the changes didn‚Äôt break any existing functionality\n\nWriting executable specifications was key to our approach. We wanted to ensure that the system was tested thoroughly while making changes. Instead of writing traditional documentation, we created executable specifications that would test the code. This approach allowed us to quickly iterate and improve the system while ensuring that the changes didn‚Äôt break any existing functionality.\nAs we progressed, we replaced the old logic in the controllers with the new libraries. We created a rudimentary feature flag system and added a guard to the old controllers. Then we added each new use case to be called when the individual feature flag was turned ON. We encountered a few failures, but they were not a cause for worry. We simply turned off the feature, wrote a new specification for the failure case, and fixed it. After the next deployment, all we needed to do was turn the feature flag back ON.\nAt this point, we had rewritten 70% of the code, with a coverage above 90%. The features introduced to the system since then have been smooth, as we would expect from a well-tested system. Even coming from a zero-coverage codebase, we were able to create a well-tested and reliable system by writing executable specifications.\nModernizing an old legacy system can be a challenging task, but with the right approach, it can be done smoothly. Our approach of keeping all the data structure intact, writing executable specifications, and adding features through feature flags proved to be effective. We were able to rewrite most of the code, increase test coverage to over 90%, and introduce new features to the system without causing any disruption."},"2023/why-deferring-the-solution-can-benefit-the-team":{"title":"Why Deferring Some Part of the Solution in Agile Can Benefit Your Development Team","links":[],"tags":["agile"],"content":"Agile is a methodology that is widely used in the software development industry. One of the key principles of Agile is that it is focused on delivering value to the customer through iterative and incremental development. To achieve this, it is recommended that teams defer some part of the solution to be explored during development rather than having well-defined tasks. In this article, we will discuss why this is important and how it can benefit a development team.\n\nFirstly, Agile is designed to be flexible and adaptable. It recognizes that requirements and priorities can change over time, and that a rigid plan can be counterproductive in such an environment. Well-defined tasks can be limiting, as they can restrict the team‚Äôs ability to respond to changing requirements. By deferring some of the solution to be explored during development, teams can remain more responsive to customer needs and better able to deliver value.\nSecondly, Agile is intended to foster collaboration and creativity. By deferring some part of the solution to be explored during development, teams are encouraged to work together to find the best solution. This can lead to more innovative and creative solutions, as the team is not constrained by pre-determined tasks. It also encourages teamwork and communication, which can be beneficial for the overall development process.\nThirdly, Agile is focused on delivering value early and often. By deferring some part of the solution to be explored during development, teams can prioritize the most valuable features and deliver them first. This means that the customer can see tangible results quickly, which can help build trust and confidence in the development team. It also means that the team can iterate and refine the solution based on feedback from the customer, which can lead to a better overall product.\nFinally, Agile is designed to be iterative and incremental. By deferring some part of the solution to be explored during development, teams can iterate on the solution and refine it over time. This can lead to a more robust and well-rounded product, as the team has had the opportunity to explore different options and approaches. It can also help mitigate risk, as the team can identify and address potential issues earlier in the development process.\nIn conclusion, deferring some part of the solution to be explored during development is a key component of the Agile methodology. It allows teams to remain flexible and adaptable, fosters collaboration and creativity, prioritizes value, and promotes iterative and incremental development. By adopting this approach, teams can deliver better results for their customers and build more effective software products."},"2023/why-organizing-code-by-feature":{"title":"Why Organizing Code by Feature is More Effective than by Type","links":[],"tags":["best-practices","code"],"content":"\nOrganizing code files and classes in a way that makes sense for the project at hand can be a daunting task for developers. One popular method for structuring code is to group files and classes by feature, rather than by type.\nWhen grouping code by feature, all of the files and classes related to a specific feature of the project are placed in the same folder. For example, all code related to user authentication would be placed in an ‚ÄúAuthentication‚Äù folder, while code related to image uploads would be placed in an ‚ÄúUploads‚Äù folder. This allows developers to quickly and easily locate the code they need to work on, as well as understand the overall structure of the project.\nOn the other hand, grouping code by type, such as placing all model classes in one folder, all views in another, and all controllers in yet another, can make it more difficult to find the code related to a specific feature. This is because the code for a feature may be spread across multiple folders, making it harder to understand the overall structure of the project.\n\nAdditionally, when grouping code by feature, it is more likely that the code will be cohesive and highly dependent on one another, promoting better code reusability, maintainability and scalability. This way, it is easier to understand the interrelated aspects of the feature, and how it all works together.\nAnother advantage of grouping code by feature is that it allows for easy separation of concerns. For instance, if a feature is to be removed or replaced, it would be as simple as removing the corresponding folder. This way, it is easier to isolate and manage the changes that are being made to the project.\nIn conclusion, grouping code files and classes by feature is a more effective way to organize code, as it allows for easy navigation, better code reusability, maintainability and scalability, and a clear separation of concerns. This approach makes it easier for developers to understand the overall structure of the project, and quickly locate the code they need to work on."},"2023/why-write-tests-first":{"title":"Why write tests first?","links":[],"tags":["tdd"],"content":"\nWriting tests before writing code, also known as Test-Driven Development (TDD), is a popular software development technique that can lead to good design. The basic idea behind TDD is to write automated tests for a piece of functionality before writing the code that implements it. This approach has many benefits, including improved code quality, better maintainability, and faster development times.\nOne of the main benefits of TDD is that it helps to ensure that the code is well-designed. When writing tests before code, developers are forced to think about how the code should behave and what inputs it should accept. This leads to a better understanding of the problem at hand and helps to identify any potential design issues early on. By writing tests first, developers can ensure that the code is easy to understand and maintain, and that it is well-suited to the task at hand.\nAnother benefit of TDD is that it helps to improve code quality. When writing tests before code, developers are encouraged to think about edge cases and possible errors that may occur. This leads to more robust code that is less likely to contain bugs. Additionally, because the tests are automated, developers can easily run them to ensure that the code is working as expected. This helps to catch any errors early on, before they become more difficult and time-consuming to fix.\nTDD also leads to faster development times. When writing tests before code, developers are able to focus on small, manageable chunks of functionality at a time. This helps to break down a large problem into smaller, more manageable pieces, making it easier to understand and solve. Additionally, because the tests are automated, developers can easily run them to ensure that the code is working as expected, reducing the need for manual testing.\nTDD also helps to improve maintainability of the code. When writing tests before code, developers are forced to think about how the code should behave and what inputs it should accept. This leads to a better understanding of the problem at hand and helps to identify any potential design issues early on. By writing tests first, developers can ensure that the code is easy to understand and maintain, and that it is well-suited to the task at hand.\nIn conclusion, writing tests before code leads to good design, and the benefits of TDD are many. It ensures that the code is well-designed, improves code quality, leads to faster development times, and improves maintainability of the code. By following this approach, developers can create better software that is more robust, reliable, and easy to maintain."},"2023/yet-another-status-report-meeting":{"title":"Yet another status report meeting","links":[],"tags":["shape-up","agile","no-meeting"],"content":"Status report meetings are a common occurrence in many workplaces. They are often seen as a necessary evil to keep everyone up-to-date on ongoing projects and to ensure that everyone is on the same page. However, the reality is that these meetings are often pointless and can be a waste of time for everyone involved.\n\nreduce the need for status report meetings, as teams are empowered to take ownership of their work and make progress independently\n\nThe main reason why purely status report meetings are pointless is that they do not provide any value. In most cases, the information that is shared in these meetings is already known to everyone involved. For example, if a team is working on a project, everyone on the team is likely aware of the progress that has been made, the challenges that have been faced, and the next steps that need to be taken.\nFurthermore, status report meetings often lack context and insights that are essential for making informed decisions. Without these elements, the information presented in the meeting is little more than a collection of data points that do not tell the full story. As a result, decisions made based on this information may not be as effective or efficient as they could be.\nAnother issue with status report meetings is that they can be a major drain on productivity. When people are required to attend meetings that do not provide any value, they are essentially wasting their time. This can be especially frustrating when people have important work that needs to be done, but they are forced to attend meetings that do not help them accomplish their goals.\nMoreover, status report meetings can be demotivating for employees. When people are required to attend meetings that they perceive as pointless, it can lower their morale and reduce their engagement. This can be especially damaging in situations where employees are already feeling overworked or undervalued.\nSo, what can be done to make status report meetings more effective and valuable? One solution is to shift the focus of the meeting from providing updates to generating insights and ideas. Instead of simply reporting on progress, team members could be encouraged to share their thoughts on how to overcome challenges and achieve goals. This approach would not only make the meeting more engaging but would also provide a forum for collaboration and innovation.\nAnother option is to reduce the frequency of status report meetings. Instead of having weekly meetings, for example, teams could have bi-weekly or monthly meetings. This approach would allow teams to focus on important topics that require discussion and provide more time for individual work.\nIn conclusion, purely status report meetings are often pointless and can be a waste of time. They do not provide any real value, lack context and insights, and can be demotivating for employees. To make these meetings more effective, teams should shift their focus to generating insights and ideas and reduce their frequency to allow for more productive and engaging discussions. By doing so, teams can maximize the value of their meetings and improve their overall productivity and performance.\n\nThe Shape Up methodology, developed by Basecamp, has generated a lot of curiosity in the tech industry due to its unique approach to project management. This methodology emphasizes the importance of giving teams the autonomy to make decisions and to focus on solving problems rather than simply following a predefined process. By focusing on outcomes rather than outputs, Shape Up encourages teams to be more innovative and creative in their approach to problem-solving. This approach can also reduce the need for status report meetings, as teams are empowered to take ownership of their work and make progress independently. By embracing the principles of Shape Up, teams can become more self-sufficient and productive, resulting in a more efficient and streamlined project management process."},"2024/nsequence":{"title":"NSequence","links":[],"tags":["hilo","dotnet","sequence-generator"],"content":"\nThe first version of NSequence, a simple yet powerful HiLo sequence generator suited for dotnet, was released today. NSequence, designed with simplicity in mind, provides an easy way to generate unique IDs for business items within your applications. What distinguishes this project is its user-friendliness, as it offers a public static method for easy integration, making it a viable option for developers that prefer a clear solution over dependency injection.\nIn the future, the NSequence package will be smoothly integrated into EventPulse examples. EventPulse is a side project that aims to simplify event sourcing without requiring changes in business classes. We can construct unique identifiers using sequential integers by introducing NSequence into EventPulse use, but with the same practical method that ‚ÄúGuid.NewGuid()‚Äù provides.\nNuget Package: www.nuget.org/packages/NSequence\nRepository: github.com/hesenger/NSequence"},"2024/uncovering-event-sourcing":{"title":"Uncovering the Essence of Event Sourcing in Everyday Systems","links":[],"tags":["event-sourcing","ddd"],"content":"\nThe idea of ‚Äúevent sourcing‚Äù has long felt very complicated to many in the software development industry. For many, it could seem like a paradigm change, but in reality, most systems are far closer to Event Sourcing than they may think.\nCRUD operations are frequently used in traditional systems to handle data. Beneath the surface, though, these systems can be thought of as being predicated on estimates produced by the event sourcing pattern. To put it another way, instead of keeping the events themselves, CRUD-based systems retain their consequences, like a change in state or an action. On the other hand, event sourcing promotes the archiving of real-world occurrences, offering a chronological account of activities.\n\nFor many, it could seem like a paradigm change, but in reality, most systems are far closer to Event Sourcing than they may think.\n\nDevelopers can use pre-existing systems and make little changes to the persistence layer to implement Event Sourcing. The system may recreate the exact same records in the CRUD tables using the stored events, as opposed to storing the resultant state directly. This method permits a more accurate portrayal of the system‚Äôs history in addition to offering a more thorough audit trail.\nThis method‚Äôs flexibility is what makes it so great ‚Äî it lets developers gradually implement Event Sourcing ideas. Developers can progressively move from a CRUD-centric approach to one based on the concepts of Event Sourcing by incorporating event storage into an existing system.\nHowever, there appears to be a disconnect between the ideal scenario suggested by classic Domain-Driven Design (DDD) and the implementation of commonly used Event Sourcing frameworks. DDD advises separating any persistence-related issues from the domain layer to provide a clear and manageable architecture.\nMany event sourcing frameworks are not up to par with this goal in practice. Developers are often obliged to adopt a less elegant solution, inheriting and contaminating the domain layer with event persistence architecture. This tampers with the domain layer‚Äôs purity, raising a number of issues that may impede code clarity and maintainability.\nTo summarize, event sourcing is not a strange notion to developers working with CRUD-based systems. Recognizing the value of recording events rather than merely their effects allows for a more realistic representation of system history. It‚Äôs critical to be aware of potential flaws in widely used frameworks, which may need a compromise in the separation of concerns advocated by basic DDD. The ability to strike the proper balance between historical accuracy and clean design will surely determine the future of event-driven programming."},"index":{"title":"Welcome to some random thoughts","links":[],"tags":[],"content":"This is my personal collection of posts around software engineering and my career in the\ntech industry. I hope you somehow enjoy the content.\nThe articles here were published on medium previously and then migrated to this due to my personal\nissues with the platform paywall that although was not enabled on my posts is disgusting and\nmakes me skip any google result for medium."}}